{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e67967-34c4-46df-b441-bc7a7f45c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vbocharnikov/.conda/envs/my_pyg/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import tqdm as tqdm\n",
    "# from tqdm import tqdm\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "from misc.utils import divide_chunks\n",
    "from dataset.vocab import Vocabulary\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "log = logger\n",
    "\n",
    "\n",
    "class TransactionDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 mlm,\n",
    "                 user_ids=None,\n",
    "                 seq_len=10,\n",
    "                 num_bins=10,\n",
    "                 cached=True,\n",
    "                 root=\"./data/card/\",\n",
    "                 fname=\"card_trans\",\n",
    "                 vocab_dir=\"checkpoints\",\n",
    "                 fextension=\"\",\n",
    "                 nrows=None,\n",
    "                 flatten=False,\n",
    "                 stride=5,\n",
    "                 adap_thres=10 ** 8,\n",
    "                 return_labels=False,\n",
    "                 skip_user=False):\n",
    "\n",
    "        self.root = root\n",
    "        self.fname = fname\n",
    "        self.nrows = nrows\n",
    "        self.fextension = f'_{fextension}' if fextension else ''\n",
    "        self.cached = cached\n",
    "        self.user_ids = user_ids\n",
    "        self.return_labels = return_labels\n",
    "        self.skip_user = skip_user\n",
    "\n",
    "        self.mlm = mlm\n",
    "        self.trans_stride = stride\n",
    "\n",
    "        self.flatten = flatten\n",
    "\n",
    "        self.vocab = Vocabulary(adap_thres)\n",
    "        self.seq_len = seq_len\n",
    "        self.encoder_fit = {}\n",
    "\n",
    "        self.trans_table = None\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.window_label = []\n",
    "\n",
    "        self.ncols = None\n",
    "        self.num_bins = num_bins\n",
    "        self.encode_data()\n",
    "        self.init_vocab()\n",
    "        self.prepare_samples()\n",
    "        self.save_vocab(vocab_dir)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.flatten:\n",
    "            return_data = torch.tensor(self.data[index], dtype=torch.long)\n",
    "        else:\n",
    "            return_data = torch.tensor(self.data[index], dtype=torch.long).reshape(self.seq_len, -1)\n",
    "\n",
    "        if self.return_labels:\n",
    "            return_data = (return_data, torch.tensor(self.labels[index], dtype=torch.long))\n",
    "\n",
    "        return return_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def save_vocab(self, vocab_dir):\n",
    "        file_name = path.join(vocab_dir, f'vocab{self.fextension}.nb')\n",
    "        log.info(f\"saving vocab at {file_name}\")\n",
    "        self.vocab.save_vocab(file_name)\n",
    "\n",
    "    @staticmethod\n",
    "    def label_fit_transform(column, enc_type=\"label\"):\n",
    "        if enc_type == \"label\":\n",
    "            mfit = LabelEncoder()\n",
    "        else:\n",
    "            mfit = MinMaxScaler()\n",
    "        mfit.fit(column)\n",
    "\n",
    "        return mfit, mfit.transform(column)\n",
    "\n",
    "    @staticmethod\n",
    "    def timeEncoder(X):\n",
    "        X_hm = X['Time'].str.split(':', expand=True)\n",
    "        d = pd.to_datetime(dict(year=X['Year'], month=X['Month'], day=X['Day'], hour=X_hm[0], minute=X_hm[1])).astype(\n",
    "            int)\n",
    "        return pd.DataFrame(d)\n",
    "\n",
    "    @staticmethod\n",
    "    def amountEncoder(X):\n",
    "        amt = X.apply(lambda x: x[1:]).astype(float).apply(lambda amt: max(1, amt)).apply(math.log)\n",
    "        return pd.DataFrame(amt)\n",
    "\n",
    "    @staticmethod\n",
    "    def fraudEncoder(X):\n",
    "        fraud = (X == 'Yes').astype(int)\n",
    "        return pd.DataFrame(fraud)\n",
    "\n",
    "    @staticmethod\n",
    "    def nanNone(X):\n",
    "        return X.where(pd.notnull(X), 'None')\n",
    "\n",
    "    @staticmethod\n",
    "    def nanZero(X):\n",
    "        return X.where(pd.notnull(X), 0)\n",
    "\n",
    "    def _quantization_binning(self, data):\n",
    "        qtls = np.arange(0.0, 1.0 + 1 / self.num_bins, 1 / self.num_bins)\n",
    "        bin_edges = np.quantile(data, qtls, axis=0)  # (num_bins + 1, num_features)\n",
    "        bin_widths = np.diff(bin_edges, axis=0)\n",
    "        bin_centers = bin_edges[:-1] + bin_widths / 2  # ()\n",
    "        return bin_edges, bin_centers, bin_widths\n",
    "\n",
    "    def _quantize(self, inputs, bin_edges):\n",
    "        quant_inputs = np.zeros(inputs.shape[0])\n",
    "        for i, x in enumerate(inputs):\n",
    "            quant_inputs[i] = np.digitize(x, bin_edges)\n",
    "        quant_inputs = quant_inputs.clip(1, self.num_bins) - 1  # Clip edges\n",
    "        return quant_inputs\n",
    "\n",
    "    def user_level_data(self):\n",
    "        fname = path.join(self.root, f\"preprocessed/{self.fname}.user{self.fextension}.pkl\")\n",
    "        trans_data, trans_labels = [], []\n",
    "\n",
    "        if self.cached and path.isfile(fname):\n",
    "            log.info(f\"loading cached user level data from {fname}\")\n",
    "            cached_data = pickle.load(open(fname, \"rb\"))\n",
    "            trans_data = cached_data[\"trans\"]\n",
    "            trans_labels = cached_data[\"labels\"]\n",
    "            columns_names = cached_data[\"columns\"]\n",
    "\n",
    "        else:\n",
    "            unique_users = self.trans_table[\"User\"].unique()\n",
    "            columns_names = list(self.trans_table.columns)\n",
    "\n",
    "            for user in tqdm.tqdm(unique_users):\n",
    "                user_data = self.trans_table.loc[self.trans_table[\"User\"] == user]\n",
    "                user_trans, user_labels = [], []\n",
    "                for idx, row in user_data.iterrows():\n",
    "                    row = list(row)\n",
    "\n",
    "                    # assumption that user is first field\n",
    "                    skip_idx = 1 if self.skip_user else 0\n",
    "\n",
    "                    user_trans.extend(row[skip_idx:-1])\n",
    "                    user_labels.append(row[-1])\n",
    "\n",
    "                trans_data.append(user_trans)\n",
    "                trans_labels.append(user_labels)\n",
    "\n",
    "            if self.skip_user:\n",
    "                columns_names.remove(\"User\")\n",
    "\n",
    "            with open(fname, 'wb') as cache_file:\n",
    "                pickle.dump({\"trans\": trans_data, \"labels\": trans_labels, \"columns\": columns_names}, cache_file)\n",
    "\n",
    "        # convert to str\n",
    "        return trans_data, trans_labels, columns_names\n",
    "\n",
    "    def format_trans(self, trans_lst, column_names):\n",
    "        trans_lst = list(divide_chunks(trans_lst, len(self.vocab.field_keys) - 2))  # 2 to ignore isFraud and SPECIAL\n",
    "        user_vocab_ids = []\n",
    "\n",
    "        sep_id = self.vocab.get_id(self.vocab.sep_token, special_token=True)\n",
    "\n",
    "        for trans in trans_lst:\n",
    "            vocab_ids = []\n",
    "            for jdx, field in enumerate(trans):\n",
    "                vocab_id = self.vocab.get_id(field, column_names[jdx])\n",
    "                vocab_ids.append(vocab_id)\n",
    "\n",
    "            # TODO : need to handle ncols when sep is not added\n",
    "            if self.mlm:  # and self.flatten:  # only add [SEP] for BERT + flatten scenario\n",
    "                vocab_ids.append(sep_id)\n",
    "\n",
    "            user_vocab_ids.append(vocab_ids)\n",
    "\n",
    "        return user_vocab_ids\n",
    "\n",
    "    def prepare_samples(self):\n",
    "        log.info(\"preparing user level data...\")\n",
    "        trans_data, trans_labels, columns_names = self.user_level_data()\n",
    "\n",
    "        log.info(\"creating transaction samples with vocab\")\n",
    "        for user_idx in tqdm.tqdm(range(len(trans_data))):\n",
    "            user_row = trans_data[user_idx]\n",
    "            user_row_ids = self.format_trans(user_row, columns_names)\n",
    "\n",
    "            user_labels = trans_labels[user_idx]\n",
    "\n",
    "            bos_token = self.vocab.get_id(self.vocab.bos_token, special_token=True)  # will be used for GPT2\n",
    "            eos_token = self.vocab.get_id(self.vocab.eos_token, special_token=True)  # will be used for GPT2\n",
    "            for jdx in range(0, len(user_row_ids) - self.seq_len + 1, self.trans_stride):\n",
    "                ids = user_row_ids[jdx:(jdx + self.seq_len)]\n",
    "                ids = [idx for ids_lst in ids for idx in ids_lst]  # flattening\n",
    "                if not self.mlm and self.flatten:  # for GPT2, need to add [BOS] and [EOS] tokens\n",
    "                    ids = [bos_token] + ids + [eos_token]\n",
    "                self.data.append(ids)\n",
    "\n",
    "            for jdx in range(0, len(user_labels) - self.seq_len + 1, self.trans_stride):\n",
    "                ids = user_labels[jdx:(jdx + self.seq_len)]\n",
    "                self.labels.append(ids)\n",
    "\n",
    "                fraud = 0\n",
    "                if len(np.nonzero(ids)[0]) > 0:\n",
    "                    fraud = 1\n",
    "                self.window_label.append(fraud)\n",
    "\n",
    "        assert len(self.data) == len(self.labels)\n",
    "\n",
    "        '''\n",
    "            ncols = total fields - 1 (special tokens) - 1 (label)\n",
    "            if bert:\n",
    "                ncols += 1 (for sep)\n",
    "        '''\n",
    "        self.ncols = len(self.vocab.field_keys) - 2 + (1 if self.mlm else 0)\n",
    "        log.info(f\"ncols: {self.ncols}\")\n",
    "        log.info(f\"no of samples {len(self.data)}\")\n",
    "\n",
    "    def get_csv(self, fname):\n",
    "        data = pd.read_csv(fname, nrows=self.nrows)\n",
    "        if self.user_ids:\n",
    "            log.info(f'Filtering data by user ids list: {self.user_ids}...')\n",
    "            self.user_ids = map(int, self.user_ids)\n",
    "            data = data[data['User'].isin(self.user_ids)]\n",
    "\n",
    "        self.nrows = data.shape[0]\n",
    "        log.info(f\"read data : {data.shape}\")\n",
    "        return data\n",
    "\n",
    "    def write_csv(self, data, fname):\n",
    "        log.info(f\"writing to file {fname}\")\n",
    "        data.to_csv(fname, index=False)\n",
    "\n",
    "    def init_vocab(self):\n",
    "        column_names = list(self.trans_table.columns)\n",
    "        if self.skip_user:\n",
    "            column_names.remove(\"User\")\n",
    "\n",
    "        self.vocab.set_field_keys(column_names)\n",
    "\n",
    "        for column in column_names:\n",
    "            unique_values = self.trans_table[column].value_counts(sort=True).to_dict()  # returns sorted\n",
    "            for val in unique_values:\n",
    "                self.vocab.set_id(val, column)\n",
    "\n",
    "        log.info(f\"total columns: {list(column_names)}\")\n",
    "        log.info(f\"total vocabulary size: {len(self.vocab.id2token)}\")\n",
    "\n",
    "        for column in self.vocab.field_keys:\n",
    "            vocab_size = len(self.vocab.token2id[column])\n",
    "            log.info(f\"column : {column}, vocab size : {vocab_size}\")\n",
    "\n",
    "            if vocab_size > self.vocab.adap_thres:\n",
    "                log.info(f\"\\tsetting {column} for adaptive softmax\")\n",
    "                self.vocab.adap_sm_cols.add(column)\n",
    "\n",
    "    def encode_data(self):\n",
    "        dirname = path.join(self.root, \"preprocessed\")\n",
    "        fname = f'{self.fname}{self.fextension}.encoded.csv'\n",
    "        data_file = path.join(self.root, f\"{self.fname}.csv\")\n",
    "\n",
    "        if self.cached and path.isfile(path.join(dirname, fname)):\n",
    "            log.info(f\"cached encoded data is read from {fname}\")\n",
    "            self.trans_table = self.get_csv(path.join(dirname, fname))\n",
    "            encoder_fname = path.join(dirname, f'{self.fname}{self.fextension}.encoder_fit.pkl')\n",
    "            self.encoder_fit = pickle.load(open(encoder_fname, \"rb\"))\n",
    "            return\n",
    "\n",
    "        data = self.get_csv(data_file)\n",
    "        log.info(f\"{data_file} is read.\")\n",
    "\n",
    "        log.info(\"nan resolution.\")\n",
    "        data['Errors?'] = self.nanNone(data['Errors?'])\n",
    "        data['Is Fraud?'] = self.fraudEncoder(data['Is Fraud?'])\n",
    "        data['Zip'] = self.nanZero(data['Zip'])\n",
    "        data['Merchant State'] = self.nanNone(data['Merchant State'])\n",
    "        data['Use Chip'] = self.nanNone(data['Use Chip'])\n",
    "        data['Amount'] = self.amountEncoder(data['Amount'])\n",
    "\n",
    "        sub_columns = ['Errors?', 'MCC', 'Zip', 'Merchant State', 'Merchant City', 'Merchant Name', 'Use Chip']\n",
    "\n",
    "        log.info(\"label-fit-transform.\")\n",
    "        for col_name in tqdm.tqdm(sub_columns):\n",
    "            col_data = data[col_name]\n",
    "            col_fit, col_data = self.label_fit_transform(col_data)\n",
    "            self.encoder_fit[col_name] = col_fit\n",
    "            data[col_name] = col_data\n",
    "\n",
    "        log.info(\"timestamp fit transform\")\n",
    "        timestamp = self.timeEncoder(data[['Year', 'Month', 'Day', 'Time']])\n",
    "        timestamp_fit, timestamp = self.label_fit_transform(timestamp, enc_type=\"time\")\n",
    "        self.encoder_fit['Timestamp'] = timestamp_fit\n",
    "        data['Timestamp'] = timestamp\n",
    "\n",
    "        log.info(\"timestamp quant transform\")\n",
    "        coldata = np.array(data['Timestamp'])\n",
    "        bin_edges, bin_centers, bin_widths = self._quantization_binning(coldata)\n",
    "        data['Timestamp'] = self._quantize(coldata, bin_edges)\n",
    "        self.encoder_fit[\"Timestamp-Quant\"] = [bin_edges, bin_centers, bin_widths]\n",
    "\n",
    "        log.info(\"amount quant transform\")\n",
    "        coldata = np.array(data['Amount'])\n",
    "        bin_edges, bin_centers, bin_widths = self._quantization_binning(coldata)\n",
    "        data['Amount'] = self._quantize(coldata, bin_edges)\n",
    "        self.encoder_fit[\"Amount-Quant\"] = [bin_edges, bin_centers, bin_widths]\n",
    "\n",
    "        columns_to_select = ['User',\n",
    "                             'Card',\n",
    "                             'Timestamp',\n",
    "                             'Amount',\n",
    "                             'Use Chip',\n",
    "                             'Merchant Name',\n",
    "                             'Merchant City',\n",
    "                             'Merchant State',\n",
    "                             'Zip',\n",
    "                             'MCC',\n",
    "                             'Errors?',\n",
    "                             'Is Fraud?']\n",
    "\n",
    "        self.trans_table = data[columns_to_select]\n",
    "\n",
    "        log.info(f\"writing cached csv to {path.join(dirname, fname)}\")\n",
    "        if not path.exists(dirname):\n",
    "            os.mkdir(dirname)\n",
    "        self.write_csv(self.trans_table, path.join(dirname, fname))\n",
    "\n",
    "        encoder_fname = path.join(dirname, f'{self.fname}{self.fextension}.encoder_fit.pkl')\n",
    "        log.info(f\"writing cached encoder fit to {encoder_fname}\")\n",
    "        pickle.dump(self.encoder_fit, open(encoder_fname, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a218c-fc5e-4e64-b606-03d3aa3c6fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888ad7c4-0d68-4261-9fc5-6353b044c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TransactionFeatureDataset(Dataset):\n",
    "#     \"\"\"Transaction Feature Dataset for Fraud Detection task.\"\"\"\n",
    "\n",
    "#     def __init__(self, data, label, with_upsample=False):\n",
    "#         \"\"\"Args:\n",
    "#             - data: sample feature extracted from TabBERT.\n",
    "#             - label: label in sample (window) level.\n",
    "#             - with_upsample: if True, upsample fraudulent data to have the same amount with non-fraudulent data.\n",
    "#         \"\"\"\n",
    "#         self.data = data\n",
    "#         self.label = label\n",
    "#         if with_upsample:\n",
    "#             self._upsample()\n",
    "\n",
    "#     def __getitem__(self, item):\n",
    "#         return self.data[item], self.label[item]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def _upsample(self):\n",
    "#         logger.info('Upsample fraudulent samples.')\n",
    "#         non_fraud = self.data[self.label == 0]\n",
    "#         fraud = self.data[self.label == 1]\n",
    "#         fraud_upsample = resample(fraud, replace=True, n_samples=non_fraud.shape[0], random_state=2022)\n",
    "#         self.data = torch.cat((fraud_upsample, non_fraud))\n",
    "#         self.label = torch.cat((torch.ones(fraud_upsample.shape[0]), torch.zeros(non_fraud.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd4413a-1ae3-4073-8d0b-a7e8b7d0fa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [08:00<00:00,  4.16it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TransactionDataset(0, fname='card_transaction.v1', return_labels=True, stride=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5864a6-0a2a-45f6-9166-7ff3c06c0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from os.path import join\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from args import define_main_parser\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "from dataset.prsa import PRSADataset\n",
    "from dataset.card import TransactionDataset\n",
    "# from models.modules import TabFormerBertLM, TabFormerGPT2\n",
    "from misc.utils import random_split_dataset\n",
    "from dataset.datacollator import TransDataCollatorForLanguageModeling\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "log = logger\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3f03b6-de09-4480-859e-c86f76da6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 52\n",
    "random.seed(seed)  # python \n",
    "np.random.seed(seed)  # numpy\n",
    "torch.manual_seed(seed)  # torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)  # torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b7b063-b0fd-4ddf-9b4f-3cad4bfb679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dataset.vocab\n",
    "custom_special_tokens = vocab.get_special_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c59b20a-21d7-40c7-80a5-6ba0432a15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train, val, test [0.6. 0.2, 0.2]\n",
    "totalN = len(dataset)\n",
    "trainN = int(0.6 * totalN)\n",
    "\n",
    "valtestN = totalN - trainN\n",
    "valN = int(valtestN * 0.5)\n",
    "testN = valtestN - valN\n",
    "\n",
    "assert totalN == trainN + valN + testN\n",
    "\n",
    "lengths = [trainN, valN, testN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a86f34d-4609-4981-9d3f-7a5c79c6f5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/12/2024 09:53:56 - INFO - __main__ -   # lengths: train [1462673]  valid [487558]  test [487558]\n",
      "09/12/2024 09:53:56 - INFO - __main__ -   # lengths: train [0.60]  valid [0.20]  test [0.20]\n"
     ]
    }
   ],
   "source": [
    "log.info(f\"# lengths: train [{trainN}]  valid [{valN}]  test [{testN}]\")\n",
    "log.info(\"# lengths: train [{:.2f}]  valid [{:.2f}]  test [{:.2f}]\".format(trainN / totalN, valN / totalN,\n",
    "                                                                           testN / totalN))\n",
    "\n",
    "train_dataset, eval_dataset, test_dataset = random_split_dataset(dataset, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a28282-eb56-4acc-b039-7b87f0637b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, label_size, batch_size, use_gpu):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.use_gpu = use_gpu\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2label = nn.Linear(hidden_dim, label_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        if self.use_gpu:\n",
    "            h0 = torch.zeros(1, self.batch_size, self.hidden_dim).cuda()\n",
    "            c0 = torch.zeros(1, self.batch_size, self.hidden_dim).cuda()\n",
    "        else:\n",
    "            h0 = torch.zeros(1, self.batch_size, self.hidden_dim)\n",
    "            c0 = torch.zeros(1, self.batch_size, self.hidden_dim)\n",
    "        return (h0, c0)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        x = embeds.view(len(sentence), self.batch_size, -1)\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        y  = self.hidden2label(lstm_out[-1])\n",
    "        return y\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "embedding_dim = 11\n",
    "hidden_dim = 1024\n",
    "batch_size = 10\n",
    "\n",
    "model = LSTMClassifier(embedding_dim=embedding_dim,hidden_dim=hidden_dim,\n",
    "                           vocab_size=143492, label_size=2, batch_size=batch_size, use_gpu=use_gpu)\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    # cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52554f9f-ca43-4793-b1a3-a3d4e2c2efaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b420a570-e8e0-4b91-a9b0-f42c143c2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'models/RawLSTM_1024.pt'\n",
    "model = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "986dbf83-209f-485b-a050-b897a6d89ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "epochs = 5\n",
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate * (0.1 ** (epoch // 10))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "train_loss_ = []\n",
    "test_loss_ = []\n",
    "train_acc_ = []\n",
    "test_acc_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6b5da0-c8df-4fb4-a38a-93f4147e31cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 31888/1462673 [01:34<1:03:39, 374.59it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "        optimizer = adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        ## training epoch\n",
    "        total_acc = 0.0\n",
    "        total_loss = 0.0\n",
    "        total = 0.0\n",
    "        for iter, traindata in enumerate(tqdm.tqdm(train_dataset)):\n",
    "            # print(iter)\n",
    "            train_inputs, train_labels = traindata\n",
    "            train_labels = torch.squeeze(train_labels)\n",
    "\n",
    "            if use_gpu:\n",
    "                train_inputs, train_labels = (train_inputs.cuda()), train_labels.cuda()\n",
    "            \n",
    "            model.zero_grad()\n",
    "            model.batch_size = len(train_labels)\n",
    "            model.hidden = model.init_hidden()\n",
    "            output = model(train_inputs.t())\n",
    "\n",
    "            loss = loss_function(output, train_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # calc training acc\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_acc += (predicted == train_labels).sum()\n",
    "            total += len(train_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        train_loss_.append(total_loss / total)\n",
    "        train_acc_.append(total_acc / total)\n",
    "        ## testing epoch\n",
    "        total_acc = 0.0\n",
    "        total_loss = 0.0\n",
    "        total = 0.0\n",
    "        for iter, testdata in enumerate(tqdm.tqdm(test_dataset)):\n",
    "            test_inputs, test_labels = testdata\n",
    "            test_labels = torch.squeeze(test_labels)\n",
    "\n",
    "            if use_gpu:\n",
    "                test_inputs, test_labels = test_inputs.cuda(), test_labels.cuda()\n",
    "            \n",
    "            model.batch_size = len(test_labels)\n",
    "            model.hidden = model.init_hidden()\n",
    "            output = model(test_inputs.t())\n",
    "\n",
    "            loss = loss_function(output, test_labels)\n",
    "\n",
    "            # calc testing acc\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_acc += (predicted == test_labels).sum()\n",
    "            total += len(test_labels)\n",
    "            total_loss += loss.item()\n",
    "        test_loss_.append(total_loss / total)\n",
    "        test_acc_.append(total_acc / total)\n",
    "\n",
    "        print('[Epoch: %3d/%3d] Training Loss: %.6f, Testing Loss: %.6f, Training Acc: %.6f, Testing Acc: %.6f'\n",
    "              % (epoch, epochs, train_loss_[epoch], test_loss_[epoch], train_acc_[epoch], test_acc_[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7ed55c7-b645-4347-9324-69ac5a77bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'models/RawLSTM_1024.pt'\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187118df-9187-41f5-9cf4-10c82703beff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f42d8f5-c7ec-4b95-923c-2e55c1f143ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487558/487558 [08:12<00:00, 989.23it/s] \n"
     ]
    }
   ],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for iter, testdata in enumerate(tqdm.tqdm(test_dataset)):\n",
    "            test_inputs, test_labels = testdata\n",
    "            test_labels = torch.squeeze(test_labels)\n",
    "\n",
    "            if use_gpu:\n",
    "                test_inputs, test_labels = test_inputs.cuda(), test_labels.cuda()\n",
    "\n",
    "            model.batch_size = len(test_labels)\n",
    "            model.hidden = model.init_hidden()\n",
    "            output = model(test_inputs.t())\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            \n",
    "            y_pred.append(predicted.tolist())\n",
    "            y_test.append(test_labels.reshape(-1).tolist())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b093a843-e111-4c69-8605-1aa67989837e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "cm = confusion_matrix(np.asarray(y_test).reshape(-1), np.asarray(y_pred).reshape(-1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad0eaca8-5032-4c35-ac50-08cf8211c70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99949366, 0.26489869])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(np.asarray(y_test).reshape(-1), np.asarray(y_pred).reshape(-1), average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2037d7-2920-4c47-aa66-5898550617af",
   "metadata": {},
   "source": [
    "array([0.99977231, 0.77586904])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [.conda-my_pyg]",
   "language": "python",
   "name": "conda-env-.conda-my_pyg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
