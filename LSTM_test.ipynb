{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "723f75e2-3f02-450c-8b6b-b4272590103c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vbocharnikov/.conda/envs/my_pyg/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import tqdm as tqdm\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "from misc.utils import divide_chunks\n",
    "from dataset.vocab import Vocabulary\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "log = logger\n",
    "\n",
    "\n",
    "class TransactionDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 mlm,\n",
    "                 user_ids=None,\n",
    "                 seq_len=10,\n",
    "                 num_bins=10,\n",
    "                 cached=True,\n",
    "                 root=\"./data/card/\",\n",
    "                 fname=\"card_trans\",\n",
    "                 vocab_dir=\"checkpoints\",\n",
    "                 fextension=\"\",\n",
    "                 nrows=None,\n",
    "                 flatten=False,\n",
    "                 stride=5,\n",
    "                 adap_thres=10 ** 8,\n",
    "                 return_labels=False,\n",
    "                 skip_user=False):\n",
    "\n",
    "        self.root = root\n",
    "        self.fname = fname\n",
    "        self.nrows = nrows\n",
    "        self.fextension = f'_{fextension}' if fextension else ''\n",
    "        self.cached = cached\n",
    "        self.user_ids = user_ids\n",
    "        self.return_labels = return_labels\n",
    "        self.skip_user = skip_user\n",
    "\n",
    "        self.mlm = mlm\n",
    "        self.trans_stride = stride\n",
    "\n",
    "        self.flatten = flatten\n",
    "\n",
    "        self.vocab = Vocabulary(adap_thres)\n",
    "        self.seq_len = seq_len\n",
    "        self.encoder_fit = {}\n",
    "\n",
    "        self.trans_table = None\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.window_label = []\n",
    "\n",
    "        self.ncols = None\n",
    "        self.num_bins = num_bins\n",
    "        self.encode_data()\n",
    "        self.init_vocab()\n",
    "        self.prepare_samples()\n",
    "        self.save_vocab(vocab_dir)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.flatten:\n",
    "            return_data = torch.tensor(self.data[index], dtype=torch.long)\n",
    "        else:\n",
    "            return_data = torch.tensor(self.data[index], dtype=torch.long).reshape(self.seq_len, -1)\n",
    "\n",
    "        if self.return_labels:\n",
    "            return_data = (return_data, torch.tensor(self.labels[index], dtype=torch.long))\n",
    "\n",
    "        return return_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def save_vocab(self, vocab_dir):\n",
    "        file_name = path.join(vocab_dir, f'vocab{self.fextension}.nb')\n",
    "        log.info(f\"saving vocab at {file_name}\")\n",
    "        self.vocab.save_vocab(file_name)\n",
    "\n",
    "    @staticmethod\n",
    "    def label_fit_transform(column, enc_type=\"label\"):\n",
    "        if enc_type == \"label\":\n",
    "            mfit = LabelEncoder()\n",
    "        else:\n",
    "            mfit = MinMaxScaler()\n",
    "        mfit.fit(column)\n",
    "\n",
    "        return mfit, mfit.transform(column)\n",
    "\n",
    "    @staticmethod\n",
    "    def timeEncoder(X):\n",
    "        X_hm = X['Time'].str.split(':', expand=True)\n",
    "        d = pd.to_datetime(dict(year=X['Year'], month=X['Month'], day=X['Day'], hour=X_hm[0], minute=X_hm[1])).astype(\n",
    "            int)\n",
    "        return pd.DataFrame(d)\n",
    "\n",
    "    @staticmethod\n",
    "    def amountEncoder(X):\n",
    "        amt = X.apply(lambda x: x[1:]).astype(float).apply(lambda amt: max(1, amt)).apply(math.log)\n",
    "        return pd.DataFrame(amt)\n",
    "\n",
    "    @staticmethod\n",
    "    def fraudEncoder(X):\n",
    "        fraud = (X == 'Yes').astype(int)\n",
    "        return pd.DataFrame(fraud)\n",
    "\n",
    "    @staticmethod\n",
    "    def nanNone(X):\n",
    "        return X.where(pd.notnull(X), 'None')\n",
    "\n",
    "    @staticmethod\n",
    "    def nanZero(X):\n",
    "        return X.where(pd.notnull(X), 0)\n",
    "\n",
    "    def _quantization_binning(self, data):\n",
    "        qtls = np.arange(0.0, 1.0 + 1 / self.num_bins, 1 / self.num_bins)\n",
    "        bin_edges = np.quantile(data, qtls, axis=0)  # (num_bins + 1, num_features)\n",
    "        bin_widths = np.diff(bin_edges, axis=0)\n",
    "        bin_centers = bin_edges[:-1] + bin_widths / 2  # ()\n",
    "        return bin_edges, bin_centers, bin_widths\n",
    "\n",
    "    def _quantize(self, inputs, bin_edges):\n",
    "        quant_inputs = np.zeros(inputs.shape[0])\n",
    "        for i, x in enumerate(inputs):\n",
    "            quant_inputs[i] = np.digitize(x, bin_edges)\n",
    "        quant_inputs = quant_inputs.clip(1, self.num_bins) - 1  # Clip edges\n",
    "        return quant_inputs\n",
    "\n",
    "    def user_level_data(self):\n",
    "        fname = path.join(self.root, f\"preprocessed/{self.fname}.user{self.fextension}.pkl\")\n",
    "        trans_data, trans_labels = [], []\n",
    "\n",
    "        if self.cached and path.isfile(fname):\n",
    "            log.info(f\"loading cached user level data from {fname}\")\n",
    "            cached_data = pickle.load(open(fname, \"rb\"))\n",
    "            trans_data = cached_data[\"trans\"]\n",
    "            trans_labels = cached_data[\"labels\"]\n",
    "            columns_names = cached_data[\"columns\"]\n",
    "\n",
    "        else:\n",
    "            unique_users = self.trans_table[\"User\"].unique()\n",
    "            columns_names = list(self.trans_table.columns)\n",
    "\n",
    "            for user in tqdm.tqdm(unique_users):\n",
    "                user_data = self.trans_table.loc[self.trans_table[\"User\"] == user]\n",
    "                user_trans, user_labels = [], []\n",
    "                for idx, row in user_data.iterrows():\n",
    "                    row = list(row)\n",
    "\n",
    "                    # assumption that user is first field\n",
    "                    skip_idx = 1 if self.skip_user else 0\n",
    "\n",
    "                    user_trans.extend(row[skip_idx:-1])\n",
    "                    user_labels.append(row[-1])\n",
    "\n",
    "                trans_data.append(user_trans)\n",
    "                trans_labels.append(user_labels)\n",
    "\n",
    "            if self.skip_user:\n",
    "                columns_names.remove(\"User\")\n",
    "\n",
    "            with open(fname, 'wb') as cache_file:\n",
    "                pickle.dump({\"trans\": trans_data, \"labels\": trans_labels, \"columns\": columns_names}, cache_file)\n",
    "\n",
    "        # convert to str\n",
    "        return trans_data, trans_labels, columns_names\n",
    "\n",
    "    def format_trans(self, trans_lst, column_names):\n",
    "        trans_lst = list(divide_chunks(trans_lst, len(self.vocab.field_keys) - 2))  # 2 to ignore isFraud and SPECIAL\n",
    "        user_vocab_ids = []\n",
    "\n",
    "        sep_id = self.vocab.get_id(self.vocab.sep_token, special_token=True)\n",
    "\n",
    "        for trans in trans_lst:\n",
    "            vocab_ids = []\n",
    "            for jdx, field in enumerate(trans):\n",
    "                vocab_id = self.vocab.get_id(field, column_names[jdx])\n",
    "                vocab_ids.append(vocab_id)\n",
    "\n",
    "            # TODO : need to handle ncols when sep is not added\n",
    "            if self.mlm:  # and self.flatten:  # only add [SEP] for BERT + flatten scenario\n",
    "                vocab_ids.append(sep_id)\n",
    "\n",
    "            user_vocab_ids.append(vocab_ids)\n",
    "\n",
    "        return user_vocab_ids\n",
    "\n",
    "    def prepare_samples(self):\n",
    "        log.info(\"preparing user level data...\")\n",
    "        trans_data, trans_labels, columns_names = self.user_level_data()\n",
    "\n",
    "        log.info(\"creating transaction samples with vocab\")\n",
    "        for user_idx in tqdm.tqdm(range(len(trans_data))):\n",
    "            user_row = trans_data[user_idx]\n",
    "            user_row_ids = self.format_trans(user_row, columns_names)\n",
    "\n",
    "            user_labels = trans_labels[user_idx]\n",
    "\n",
    "            bos_token = self.vocab.get_id(self.vocab.bos_token, special_token=True)  # will be used for GPT2\n",
    "            eos_token = self.vocab.get_id(self.vocab.eos_token, special_token=True)  # will be used for GPT2\n",
    "            for jdx in range(0, len(user_row_ids) - self.seq_len + 1, self.trans_stride):\n",
    "                ids = user_row_ids[jdx:(jdx + self.seq_len)]\n",
    "                ids = [idx for ids_lst in ids for idx in ids_lst]  # flattening\n",
    "                if not self.mlm and self.flatten:  # for GPT2, need to add [BOS] and [EOS] tokens\n",
    "                    ids = [bos_token] + ids + [eos_token]\n",
    "                self.data.append(ids)\n",
    "\n",
    "            for jdx in range(0, len(user_labels) - self.seq_len + 1, self.trans_stride):\n",
    "                ids = user_labels[jdx:(jdx + self.seq_len)]\n",
    "                self.labels.append(ids)\n",
    "\n",
    "                fraud = 0\n",
    "                if len(np.nonzero(ids)[0]) > 0:\n",
    "                    fraud = 1\n",
    "                self.window_label.append(fraud)\n",
    "\n",
    "        assert len(self.data) == len(self.labels)\n",
    "\n",
    "        '''\n",
    "            ncols = total fields - 1 (special tokens) - 1 (label)\n",
    "            if bert:\n",
    "                ncols += 1 (for sep)\n",
    "        '''\n",
    "        self.ncols = len(self.vocab.field_keys) - 2 + (1 if self.mlm else 0)\n",
    "        log.info(f\"ncols: {self.ncols}\")\n",
    "        log.info(f\"no of samples {len(self.data)}\")\n",
    "\n",
    "    def get_csv(self, fname):\n",
    "        data = pd.read_csv(fname, nrows=self.nrows)\n",
    "        if self.user_ids:\n",
    "            log.info(f'Filtering data by user ids list: {self.user_ids}...')\n",
    "            self.user_ids = map(int, self.user_ids)\n",
    "            data = data[data['User'].isin(self.user_ids)]\n",
    "\n",
    "        self.nrows = data.shape[0]\n",
    "        log.info(f\"read data : {data.shape}\")\n",
    "        return data\n",
    "\n",
    "    def write_csv(self, data, fname):\n",
    "        log.info(f\"writing to file {fname}\")\n",
    "        data.to_csv(fname, index=False)\n",
    "\n",
    "    def init_vocab(self):\n",
    "        column_names = list(self.trans_table.columns)\n",
    "        if self.skip_user:\n",
    "            column_names.remove(\"User\")\n",
    "\n",
    "        self.vocab.set_field_keys(column_names)\n",
    "\n",
    "        for column in column_names:\n",
    "            unique_values = self.trans_table[column].value_counts(sort=True).to_dict()  # returns sorted\n",
    "            for val in unique_values:\n",
    "                self.vocab.set_id(val, column)\n",
    "\n",
    "        log.info(f\"total columns: {list(column_names)}\")\n",
    "        log.info(f\"total vocabulary size: {len(self.vocab.id2token)}\")\n",
    "\n",
    "        for column in self.vocab.field_keys:\n",
    "            vocab_size = len(self.vocab.token2id[column])\n",
    "            log.info(f\"column : {column}, vocab size : {vocab_size}\")\n",
    "\n",
    "            if vocab_size > self.vocab.adap_thres:\n",
    "                log.info(f\"\\tsetting {column} for adaptive softmax\")\n",
    "                self.vocab.adap_sm_cols.add(column)\n",
    "\n",
    "    def encode_data(self):\n",
    "        dirname = path.join(self.root, \"preprocessed\")\n",
    "        fname = f'{self.fname}{self.fextension}.encoded.csv'\n",
    "        data_file = path.join(self.root, f\"{self.fname}.csv\")\n",
    "\n",
    "        if self.cached and path.isfile(path.join(dirname, fname)):\n",
    "            log.info(f\"cached encoded data is read from {fname}\")\n",
    "            self.trans_table = self.get_csv(path.join(dirname, fname))\n",
    "            encoder_fname = path.join(dirname, f'{self.fname}{self.fextension}.encoder_fit.pkl')\n",
    "            self.encoder_fit = pickle.load(open(encoder_fname, \"rb\"))\n",
    "            return\n",
    "\n",
    "        data = self.get_csv(data_file)\n",
    "        log.info(f\"{data_file} is read.\")\n",
    "\n",
    "        log.info(\"nan resolution.\")\n",
    "        data['Errors?'] = self.nanNone(data['Errors?'])\n",
    "        data['Is Fraud?'] = self.fraudEncoder(data['Is Fraud?'])\n",
    "        data['Zip'] = self.nanZero(data['Zip'])\n",
    "        data['Merchant State'] = self.nanNone(data['Merchant State'])\n",
    "        data['Use Chip'] = self.nanNone(data['Use Chip'])\n",
    "        data['Amount'] = self.amountEncoder(data['Amount'])\n",
    "\n",
    "        sub_columns = ['Errors?', 'MCC', 'Zip', 'Merchant State', 'Merchant City', 'Merchant Name', 'Use Chip']\n",
    "\n",
    "        log.info(\"label-fit-transform.\")\n",
    "        for col_name in tqdm.tqdm(sub_columns):\n",
    "            col_data = data[col_name]\n",
    "            col_fit, col_data = self.label_fit_transform(col_data)\n",
    "            self.encoder_fit[col_name] = col_fit\n",
    "            data[col_name] = col_data\n",
    "\n",
    "        log.info(\"timestamp fit transform\")\n",
    "        timestamp = self.timeEncoder(data[['Year', 'Month', 'Day', 'Time']])\n",
    "        timestamp_fit, timestamp = self.label_fit_transform(timestamp, enc_type=\"time\")\n",
    "        self.encoder_fit['Timestamp'] = timestamp_fit\n",
    "        data['Timestamp'] = timestamp\n",
    "\n",
    "        log.info(\"timestamp quant transform\")\n",
    "        coldata = np.array(data['Timestamp'])\n",
    "        bin_edges, bin_centers, bin_widths = self._quantization_binning(coldata)\n",
    "        data['Timestamp'] = self._quantize(coldata, bin_edges)\n",
    "        self.encoder_fit[\"Timestamp-Quant\"] = [bin_edges, bin_centers, bin_widths]\n",
    "\n",
    "        log.info(\"amount quant transform\")\n",
    "        coldata = np.array(data['Amount'])\n",
    "        bin_edges, bin_centers, bin_widths = self._quantization_binning(coldata)\n",
    "        data['Amount'] = self._quantize(coldata, bin_edges)\n",
    "        self.encoder_fit[\"Amount-Quant\"] = [bin_edges, bin_centers, bin_widths]\n",
    "\n",
    "        columns_to_select = ['User',\n",
    "                             'Card',\n",
    "                             'Timestamp',\n",
    "                             'Amount',\n",
    "                             'Use Chip',\n",
    "                             'Merchant Name',\n",
    "                             'Merchant City',\n",
    "                             'Merchant State',\n",
    "                             'Zip',\n",
    "                             'MCC',\n",
    "                             'Errors?',\n",
    "                             'Is Fraud?']\n",
    "\n",
    "        self.trans_table = data[columns_to_select]\n",
    "\n",
    "        log.info(f\"writing cached csv to {path.join(dirname, fname)}\")\n",
    "        if not path.exists(dirname):\n",
    "            os.mkdir(dirname)\n",
    "        self.write_csv(self.trans_table, path.join(dirname, fname))\n",
    "\n",
    "        encoder_fname = path.join(dirname, f'{self.fname}{self.fextension}.encoder_fit.pkl')\n",
    "        log.info(f\"writing cached encoder fit to {encoder_fname}\")\n",
    "        pickle.dump(self.encoder_fit, open(encoder_fname, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a218c-fc5e-4e64-b606-03d3aa3c6fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888ad7c4-0d68-4261-9fc5-6353b044c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TransactionFeatureDataset(Dataset):\n",
    "#     \"\"\"Transaction Feature Dataset for Fraud Detection task.\"\"\"\n",
    "\n",
    "#     def __init__(self, data, label, with_upsample=False):\n",
    "#         \"\"\"Args:\n",
    "#             - data: sample feature extracted from TabBERT.\n",
    "#             - label: label in sample (window) level.\n",
    "#             - with_upsample: if True, upsample fraudulent data to have the same amount with non-fraudulent data.\n",
    "#         \"\"\"\n",
    "#         self.data = data\n",
    "#         self.label = label\n",
    "#         if with_upsample:\n",
    "#             self._upsample()\n",
    "\n",
    "#     def __getitem__(self, item):\n",
    "#         return self.data[item], self.label[item]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def _upsample(self):\n",
    "#         logger.info('Upsample fraudulent samples.')\n",
    "#         non_fraud = self.data[self.label == 0]\n",
    "#         fraud = self.data[self.label == 1]\n",
    "#         fraud_upsample = resample(fraud, replace=True, n_samples=non_fraud.shape[0], random_state=2022)\n",
    "#         self.data = torch.cat((fraud_upsample, non_fraud))\n",
    "#         self.label = torch.cat((torch.ones(fraud_upsample.shape[0]), torch.zeros(non_fraud.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd4413a-1ae3-4073-8d0b-a7e8b7d0fa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [07:03<00:00,  4.72it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TransactionDataset(0, fname='card_transaction.v1', return_labels=True, stride=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5864a6-0a2a-45f6-9166-7ff3c06c0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from os.path import join\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from args import define_main_parser\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "from dataset.prsa import PRSADataset\n",
    "from dataset.card import TransactionDataset\n",
    "# from models.modules import TabFormerBertLM, TabFormerGPT2\n",
    "from misc.utils import random_split_dataset\n",
    "from dataset.datacollator import TransDataCollatorForLanguageModeling\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "log = logger\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca3f03b6-de09-4480-859e-c86f76da6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 52\n",
    "random.seed(seed)  # python \n",
    "np.random.seed(seed)  # numpy\n",
    "torch.manual_seed(seed)  # torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)  # torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b7b063-b0fd-4ddf-9b4f-3cad4bfb679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dataset.vocab\n",
    "custom_special_tokens = vocab.get_special_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c59b20a-21d7-40c7-80a5-6ba0432a15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train, val, test [0.6. 0.2, 0.2]\n",
    "totalN = len(dataset)\n",
    "trainN = int(0.6 * totalN)\n",
    "\n",
    "valtestN = totalN - trainN\n",
    "valN = int(valtestN * 0.5)\n",
    "testN = valtestN - valN\n",
    "\n",
    "assert totalN == trainN + valN + testN\n",
    "\n",
    "lengths = [trainN, valN, testN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a86f34d-4609-4981-9d3f-7a5c79c6f5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/26/2024 08:44:28 - INFO - __main__ -   # lengths: train [1462673]  valid [487558]  test [487558]\n",
      "08/26/2024 08:44:28 - INFO - __main__ -   # lengths: train [0.60]  valid [0.20]  test [0.20]\n"
     ]
    }
   ],
   "source": [
    "log.info(f\"# lengths: train [{trainN}]  valid [{valN}]  test [{testN}]\")\n",
    "log.info(\"# lengths: train [{:.2f}]  valid [{:.2f}]  test [{:.2f}]\".format(trainN / totalN, valN / totalN,\n",
    "                                                                           testN / totalN))\n",
    "\n",
    "train_dataset, eval_dataset, test_dataset = random_split_dataset(dataset, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92a28282-eb56-4acc-b039-7b87f0637b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, label_size, batch_size, use_gpu):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.use_gpu = use_gpu\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2label = nn.Linear(hidden_dim, label_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        if self.use_gpu:\n",
    "            h0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim).cuda())\n",
    "            c0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim).cuda())\n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim))\n",
    "            c0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim))\n",
    "        return (h0, c0)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        x = embeds.view(len(sentence), self.batch_size, -1)\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        y  = self.hidden2label(lstm_out[-1])\n",
    "        return y\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "embedding_dim = 11\n",
    "hidden_dim = 64\n",
    "batch_size = 10\n",
    "\n",
    "model = LSTMClassifier(embedding_dim=embedding_dim,hidden_dim=hidden_dim,\n",
    "                           vocab_size=143492, label_size=2, batch_size=batch_size, use_gpu=use_gpu)\n",
    "if use_gpu:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "986dbf83-209f-485b-a050-b897a6d89ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "epochs = 4\n",
    "batch_size = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate * (0.1 ** (epoch // 10))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return optimizer\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "train_loss_ = []\n",
    "test_loss_ = []\n",
    "train_acc_ = []\n",
    "test_acc_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6b5da0-c8df-4fb4-a38a-93f4147e31cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 691060/1462673 [16:48<20:27, 628.40it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "        optimizer = adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        ## training epoch\n",
    "        total_acc = 0.0\n",
    "        total_loss = 0.0\n",
    "        total = 0.0\n",
    "        for iter, traindata in enumerate(tqdm(train_dataset)):\n",
    "            # print(iter)\n",
    "            train_inputs, train_labels = traindata\n",
    "            train_labels = torch.squeeze(train_labels)\n",
    "\n",
    "            if use_gpu:\n",
    "                train_inputs, train_labels = Variable(train_inputs.cuda()), train_labels.cuda()\n",
    "            else: troutputn_inputs = Variable(train_inputs)\n",
    "\n",
    "            model.zero_grad()\n",
    "            model.batch_size = len(train_labels)\n",
    "            model.hidden = model.init_hidden()\n",
    "            output = model(train_inputs.t())\n",
    "\n",
    "            loss = loss_function(output, Variable(train_labels))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # calc training acc\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_acc += (predicted == train_labels).sum()\n",
    "            total += len(train_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        train_loss_.append(total_loss / total)\n",
    "        train_acc_.append(total_acc / total)\n",
    "        ## testing epoch\n",
    "        total_acc = 0.0\n",
    "        total_loss = 0.0\n",
    "        total = 0.0\n",
    "        for iter, testdata in enumerate(tqdm(test_dataset)):\n",
    "            test_inputs, test_labels = testdata\n",
    "            test_labels = torch.squeeze(test_labels)\n",
    "\n",
    "            if use_gpu:\n",
    "                test_inputs, test_labels = Variable(test_inputs.cuda()), test_labels.cuda()\n",
    "            else: test_inputs = Variable(test_inputs)\n",
    "\n",
    "            model.batch_size = len(test_labels)\n",
    "            model.hidden = model.init_hidden()\n",
    "            output = model(test_inputs.t())\n",
    "\n",
    "            loss = loss_function(output, Variable(test_labels))\n",
    "\n",
    "            # calc testing acc\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_acc += (predicted == test_labels).sum()\n",
    "            total += len(test_labels)\n",
    "            total_loss += loss.item()\n",
    "        test_loss_.append(total_loss / total)\n",
    "        test_acc_.append(total_acc / total)\n",
    "\n",
    "        print('[Epoch: %3d/%3d] Training Loss: %.6f, Testing Loss: %.6f, Training Acc: %.6f, Testing Acc: %.6f'\n",
    "              % (epoch, epochs, train_loss_[epoch], test_loss_[epoch], train_acc_[epoch], test_acc_[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fa30bcd-19c0-44eb-8075-24be31d5d61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487558/487558 [04:13<00:00, 1920.60it/s]\n"
     ]
    }
   ],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for iter, testdata in enumerate(tqdm(test_dataset)):\n",
    "            test_inputs, test_labels = testdata\n",
    "            test_labels = torch.squeeze(test_labels)\n",
    "\n",
    "            if use_gpu:\n",
    "                test_inputs, test_labels = Variable(test_inputs.cuda()), test_labels.cuda()\n",
    "            else: test_inputs = Variable(test_inputs)\n",
    "\n",
    "            model.batch_size = len(test_labels)\n",
    "            model.hidden = model.init_hidden()\n",
    "            output = model(test_inputs.t())\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            \n",
    "            y_pred.append(predicted.tolist())\n",
    "            y_test.append(test_labels.reshape(-1).tolist())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b093a843-e111-4c69-8605-1aa67989837e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "cm = confusion_matrix(np.asarray(y_test).reshape(-1), np.asarray(y_pred).reshape(-1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad0eaca8-5032-4c35-ac50-08cf8211c70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99977231, 0.77586904])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(np.asarray(y_test).reshape(-1), np.asarray(y_pred).reshape(-1), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46bd9415-a1d6-43e4-9851-be8b494d72c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "epochs = 4\n",
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate * (0.1 ** (epoch // 10))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return optimizer\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "train_loss_ = []\n",
    "test_loss_ = []\n",
    "train_acc_ = []\n",
    "test_acc_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfbb00b-c85b-4e35-81bd-0b8fd2192e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1462673/1462673 [33:01<00:00, 738.01it/s]\n",
      "100%|██████████| 487558/487558 [04:44<00:00, 1712.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:   0/  4] Training Loss: 0.000284, Testing Loss: 0.000282, Training Acc: 0.999532, Testing Acc: 0.999548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1462673/1462673 [33:30<00:00, 727.37it/s] \n",
      "100%|██████████| 487558/487558 [04:41<00:00, 1732.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:   1/  4] Training Loss: 0.000282, Testing Loss: 0.000281, Training Acc: 0.999536, Testing Acc: 0.999551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 225182/1462673 [05:12<24:20, 847.44it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "        optimizer = adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        ## training epoch\n",
    "        total_acc = 0.0\n",
    "        total_loss = 0.0\n",
    "        total = 0.0\n",
    "        for iter, traindata in enumerate(tqdm(train_dataset)):\n",
    "            # print(iter)\n",
    "            train_inputs, train_labels = traindata\n",
    "            train_labels = torch.squeeze(train_labels)\n",
    "\n",
    "            if use_gpu:\n",
    "                train_inputs, train_labels = Variable(train_inputs.cuda()), train_labels.cuda()\n",
    "            else: troutputn_inputs = Variable(train_inputs)\n",
    "\n",
    "            model.zero_grad()\n",
    "            model.batch_size = len(train_labels)\n",
    "            model.hidden = model.init_hidden()\n",
    "            output = model(train_inputs.t())\n",
    "\n",
    "            loss = loss_function(output, Variable(train_labels))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # calc training acc\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_acc += (predicted == train_labels).sum()\n",
    "            total += len(train_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        train_loss_.append(total_loss / total)\n",
    "        train_acc_.append(total_acc / total)\n",
    "        ## testing epoch\n",
    "        total_acc = 0.0\n",
    "        total_loss = 0.0\n",
    "        total = 0.0\n",
    "        for iter, testdata in enumerate(tqdm(test_dataset)):\n",
    "            test_inputs, test_labels = testdata\n",
    "            test_labels = torch.squeeze(test_labels)\n",
    "\n",
    "            if use_gpu:\n",
    "                test_inputs, test_labels = Variable(test_inputs.cuda()), test_labels.cuda()\n",
    "            else: test_inputs = Variable(test_inputs)\n",
    "\n",
    "            model.batch_size = len(test_labels)\n",
    "            model.hidden = model.init_hidden()\n",
    "            output = model(test_inputs.t())\n",
    "\n",
    "            loss = loss_function(output, Variable(test_labels))\n",
    "\n",
    "            # calc testing acc\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_acc += (predicted == test_labels).sum()\n",
    "            total += len(test_labels)\n",
    "            total_loss += loss.item()\n",
    "        test_loss_.append(total_loss / total)\n",
    "        test_acc_.append(total_acc / total)\n",
    "\n",
    "        print('[Epoch: %3d/%3d] Training Loss: %.6f, Testing Loss: %.6f, Training Acc: %.6f, Testing Acc: %.6f'\n",
    "              % (epoch, epochs, train_loss_[epoch], test_loss_[epoch], train_acc_[epoch], test_acc_[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa65de-f607-4887-b15d-e573cd09018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(np.asarray(y_test).reshape(-1), np.asarray(y_pred).reshape(-1), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0c292-eb56-47b4-8460-1886185f2a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [.conda-my_pyg]",
   "language": "python",
   "name": "conda-env-.conda-my_pyg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
